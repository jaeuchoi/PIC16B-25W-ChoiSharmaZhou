{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/IAM_Correct.zip"
      ],
      "metadata": {
        "id": "1gDco4wvYeBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdWp5oi_XZIb",
        "outputId": "c01b014a-8af3-4e21-d9f0-fdd3164cfd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 16.7275, Val Loss: 13.1648\n",
            "Epoch [2/50], Loss: 13.7482, Val Loss: 12.4942\n",
            "Epoch [3/50], Loss: 13.2128, Val Loss: 12.1312\n",
            "Epoch [4/50], Loss: 12.9496, Val Loss: 12.1484\n",
            "Epoch [5/50], Loss: 12.7559, Val Loss: 11.8529\n",
            "Epoch [6/50], Loss: 12.5726, Val Loss: 11.7964\n",
            "Epoch [7/50], Loss: 12.3963, Val Loss: 11.6960\n",
            "Epoch [8/50], Loss: 12.2310, Val Loss: 11.2938\n",
            "Epoch [9/50], Loss: 12.0380, Val Loss: 11.1781\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import string\n",
        "import random\n",
        "from flax import linen as nn\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "# ======= Character Set for IAM Dataset =======\n",
        "CHARS = string.ascii_lowercase + string.digits + \".,;:'\\\"!?()&- \"\n",
        "char_to_index = {char: i + 1 for i, char in enumerate(CHARS)}  # Start from 1 (0 is blank)\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}  # Converts indices back into characters\n",
        "\n",
        "class IAMDataset:\n",
        "    def __init__(self, img_root, label_file, img_size=(32, 128)):\n",
        "        self.img_root = img_root\n",
        "        self.img_size = img_size\n",
        "        self.valid_samples = []\n",
        "\n",
        "        with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                if line.startswith(\"#\"):\n",
        "                    continue\n",
        "                parts = line.strip().split(\" \")\n",
        "                img_name = parts[0]\n",
        "                text = \" \".join(parts[8:]).lower()\n",
        "                label = [char_to_index[c] for c in text if c in char_to_index]\n",
        "                folder1, folder2 = img_name.split(\"-\")[:2]\n",
        "                img_path = os.path.normpath(os.path.join(self.img_root, folder1, f\"{folder1}-{folder2}\", img_name + \".png\"))\n",
        "\n",
        "                if os.path.exists(img_path) and self._is_valid_image(img_path):\n",
        "                    self.valid_samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.valid_samples[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"L\")\n",
        "            image = image.resize((128, 32), Image.BILINEAR)\n",
        "            image = np.array(image, dtype=np.float32) / 255.0\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "            return image, jnp.array(label, dtype=jnp.int32)\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            return None\n",
        "\n",
        "    def _is_valid_image(self, img_path):\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                img.verify()\n",
        "            return True\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            return False\n",
        "\n",
        "# ======= Data Loader Function for JAX =======\n",
        "def jax_dataloader(dataset, batch_size=32, shuffle=True):\n",
        "    indices = list(range(len(dataset)))\n",
        "    if shuffle:\n",
        "        random.shuffle(indices)\n",
        "\n",
        "    for start in range(0, len(indices), batch_size):\n",
        "        batch_indices = indices[start:start + batch_size]\n",
        "        batch_samples = [dataset[i] for i in batch_indices if dataset[i] is not None]\n",
        "\n",
        "        if len(batch_samples) == 0:\n",
        "            continue\n",
        "\n",
        "        images, labels = zip(*batch_samples)\n",
        "        images = jnp.stack(images)\n",
        "\n",
        "        max_label_length = max(len(label) for label in labels)\n",
        "        padded_labels = jnp.array([\n",
        "            jnp.pad(label, (0, max_label_length - len(label)), constant_values=0)\n",
        "            for label in labels\n",
        "        ])\n",
        "\n",
        "        yield images, padded_labels, jnp.array([len(label) for label in labels])\n",
        "\n",
        "# ======= CRNN Model =======\n",
        "class CRNN(nn.Module):\n",
        "    img_height: int\n",
        "    num_classes: int\n",
        "    lstm_hidden_size: int = 256\n",
        "\n",
        "    def setup(self):\n",
        "        self.conv1 = nn.Conv(features=64, kernel_size=(3, 3), strides=1, padding='SAME', dtype=jnp.float32)\n",
        "        self.conv2 = nn.Conv(features=128, kernel_size=(3, 3), strides=1, padding='SAME', dtype=jnp.float32)\n",
        "        self.fc = nn.Dense(features=self.num_classes)\n",
        "        self.lstm = nn.scan(\n",
        "            nn.LSTMCell,\n",
        "            variable_broadcast=\"params\",\n",
        "            split_rngs={\"params\": False},\n",
        "            in_axes=1,\n",
        "            out_axes=1,\n",
        "        )(features=self.lstm_hidden_size)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = nn.relu(self.conv1(x))\n",
        "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='SAME')\n",
        "        x = nn.relu(self.conv2(x))\n",
        "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2), padding='SAME')\n",
        "\n",
        "        b, c, h, w = x.shape\n",
        "        x = x.reshape(b, w, c * h)\n",
        "\n",
        "        carry = (\n",
        "            jnp.zeros((b, self.lstm_hidden_size)),\n",
        "            jnp.zeros((b, self.lstm_hidden_size)),\n",
        "        )\n",
        "        _, lstm_out = self.lstm(carry, x)\n",
        "        output = self.fc(lstm_out.reshape(-1, self.lstm_hidden_size))\n",
        "        output = output.reshape(b, w, self.num_classes)\n",
        "\n",
        "        return jax.nn.log_softmax(output, axis=-1)\n",
        "\n",
        "# ======= Compute Loss Function =======\n",
        "def loss_fn(params, images, labels):\n",
        "    logits = model.apply(params, images)\n",
        "    logit_paddings = jnp.zeros((logits.shape[0], logits.shape[1]), dtype=jnp.float32)\n",
        "    label_paddings = (labels == 0).astype(jnp.float32)\n",
        "    loss = optax.ctc_loss(logits, logit_paddings, labels, label_paddings)\n",
        "    return loss.mean()\n",
        "\n",
        "# ======= Training Function =======\n",
        "@jax.jit\n",
        "def train_step(params, opt_state, images, labels):\n",
        "    loss, grads = jax.value_and_grad(loss_fn)(params, images, labels)\n",
        "    loss = jnp.nan_to_num(loss, nan=0.0)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state, loss\n",
        "\n",
        "# ======= Validation Function =======\n",
        "def evaluate_model(dataset):\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    for images, labels, label_lengths in jax_dataloader(dataset, batch_size=32, shuffle=False):\n",
        "        loss = loss_fn(params, images, labels)\n",
        "        total_loss += loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "    return total_loss / batch_count if batch_count > 0 else float(\"inf\")\n",
        "\n",
        "# ======= Train Model Function =======\n",
        "def train_model(train_dataset, val_dataset, epochs=10):\n",
        "    global params, opt_state\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for images, labels, label_lengths in jax_dataloader(train_dataset, batch_size=32):\n",
        "            params, opt_state, loss = train_step(params, opt_state, images, labels)\n",
        "            if loss == 0.0:\n",
        "                continue\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "        avg_train_loss = epoch_loss / batch_count if batch_count > 0 else float(\"inf\")\n",
        "        val_loss = evaluate_model(val_dataset)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# ======= Training Configuration =======\n",
        "img_dir = \"/content/iam_words/words\"\n",
        "label_file = \"/content/iam_words/words.txt\"\n",
        "\n",
        "dataset = IAMDataset(img_dir, label_file)\n",
        "dataset_size = len(dataset)\n",
        "split_idx = int(0.8 * dataset_size)\n",
        "\n",
        "train_dataset = IAMDataset(img_dir, label_file)\n",
        "val_dataset = IAMDataset(img_dir, label_file)\n",
        "train_dataset.valid_samples = dataset.valid_samples[:split_idx]\n",
        "val_dataset.valid_samples = dataset.valid_samples[split_idx:]\n",
        "\n",
        "num_classes = len(CHARS) + 1\n",
        "model = CRNN(img_height=32, num_classes=num_classes)\n",
        "params = model.init(jax.random.PRNGKey(0), jnp.ones((1, 1, 32, 128)))\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "train_model(train_dataset, val_dataset, epochs=50)"
      ]
    }
  ]
}